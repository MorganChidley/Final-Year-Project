{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIcC7Pmz2zirc9qqwGwDcf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MorganChidley/Final-Year-Project/blob/main/ml_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA/Feature Engineering"
      ],
      "metadata": {
        "id": "obPiia5Kh1Xs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing original dataset**"
      ],
      "metadata": {
        "id": "X9e5opQT7znK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJ3Ye1r9bkHy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"MyDataSET.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the data\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Displaying number of Rows and Columns**"
      ],
      "metadata": {
        "id": "8F0zgoXH77wZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"MyDataSET.csv\"\n",
        "data= pd.read_csv(file_path)\n",
        "\n",
        "# Get the shape of the data (number of rows and columns)\n",
        "data.shape"
      ],
      "metadata": {
        "id": "cpYLf_EHq8YY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking dataset for missing values**"
      ],
      "metadata": {
        "id": "YjS2zmqK8FvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"MyDataSET.csv\"\n",
        "data= pd.read_csv(file_path)\n",
        "\n",
        "# Check for missing values\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "gV_JXeZArJG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removing duplicates from dataset**"
      ],
      "metadata": {
        "id": "saK37IQw8JkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"MyDataSET.csv\"\n",
        "data= pd.read_csv(file_path)\n",
        "\n",
        "# Remove duplicate rows\n",
        "data.drop_duplicates(inplace=True)\n",
        "\n",
        "# Check the new shape of the dataset\n",
        "data.shape\n",
        "\n"
      ],
      "metadata": {
        "id": "CeT-QjqGra0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Extraction**"
      ],
      "metadata": {
        "id": "J5gBj2uD8kAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "# Feature extraction functions\n",
        "\n",
        "def url_length(url):\n",
        "    \"\"\"Returns the length of the URL.\"\"\"\n",
        "    return len(url)\n",
        "\n",
        "def has_ip_address(url):\n",
        "    \"\"\"Checks if the URL contains an IP address.\"\"\"\n",
        "    ip_pattern = r\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\"\n",
        "    return 1 if re.search(ip_pattern, url) else 0\n",
        "\n",
        "def count_special_chars(url):\n",
        "    \"\"\"Counts occurrences of special characters.\"\"\"\n",
        "    special_chars = [\"-\", \"_\", \"%\", \"/\", \".\", \"#\"]\n",
        "    return {char: url.count(char) for char in special_chars}\n",
        "\n",
        "def count_subdomains(url):\n",
        "    \"\"\"Counts the number of subdomains.\"\"\"\n",
        "    parsed_url = urlparse(url).netloc\n",
        "    return parsed_url.count('.')\n",
        "\n",
        "def has_https(url):\n",
        "    \"\"\"Checks if the URL uses HTTPS.\"\"\"\n",
        "    return 1 if urlparse(url).scheme == \"https\" else 0\n",
        "\n",
        "\n",
        "def count_query_parameters(url):\n",
        "    \"\"\"Counts the number of query parameters in the URL.\"\"\"\n",
        "    query = urlparse(url).query\n",
        "    return len(query.split(\"&\")) if query else 0\n",
        "\n",
        "# Apply feature extraction\n",
        "\n",
        "data[\"url_length\"] = data[\"URL\"].apply(url_length)\n",
        "data[\"subdomain_count\"] = data[\"URL\"].apply(count_subdomains)\n",
        "data[\"https\"] = data[\"URL\"].apply(has_https)\n",
        "data[\"has_ip_address\"] = data[\"URL\"].apply(has_ip_address)\n",
        "data[\"query_parameters_count\"] = data[\"URL\"].apply(count_query_parameters)\n",
        "\n",
        "# Extract special character counts only once\n",
        "if not all(char in data.columns for char in [\"-\", \"_\", \"%\", \"/\", \".\", \"#\"]):\n",
        "    special_chars_df = data[\"URL\"].apply(count_special_chars).apply(pd.Series)\n",
        "    data = pd.concat([data, special_chars_df], axis=1)\n",
        "\n",
        "# Remove duplicate columns\n",
        "data = data.loc[:, ~data.columns.duplicated()]\n",
        "\n",
        "# Converts all feature changes to a new csv file\n",
        "data.to_csv(\"modified_dataset.csv\", index=False)\n",
        "\n",
        "# Display first few rows with new features\n",
        "data.head()"
      ],
      "metadata": {
        "id": "FbqSXhZ37UZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deploying Histogram**"
      ],
      "metadata": {
        "id": "xEouuJkU8v53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#Load Dataset\n",
        "data = pd.read_csv(\"modified_dataset.csv\")\n",
        "\n",
        "# Drop the 'ClassLabel' column\n",
        "data = data.drop('ClassLabel', axis=1)\n",
        "\n",
        "data.hist(figsize=(15, 30))  # Adjust figsize as needed\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jBFIdU2YYEgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deploying Correlation matrix**"
      ],
      "metadata": {
        "id": "a44FQoAE85XR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#Load Dataset\n",
        "data = pd.read_csv(\"modified_dataset.csv\")\n",
        "\n",
        "# Drop the 'ClassLabel' column\n",
        "data = data.drop('ClassLabel', axis=1)\n",
        "\n",
        "# Select numeric columns\n",
        "numeric_data = data.select_dtypes(include=np.number)\n",
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = numeric_data.corr()\n",
        "\n",
        "# Display correlation matrix as a styled table\n",
        "correlation_table = correlation_matrix.style.background_gradient(cmap='coolwarm')\n",
        "\n",
        "correlation_table"
      ],
      "metadata": {
        "id": "a21Wh-36epOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deploying Mutual Information**"
      ],
      "metadata": {
        "id": "S6WQ4Kn88_aQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from IPython.display import display # Import for display function\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv(\"modified_dataset.csv\")\n",
        "\n",
        "X = data.drop(['ClassLabel', \"URL\"], axis=1)\n",
        "y = data['ClassLabel']\n",
        "\n",
        "# Mutual Information\n",
        "mutual_info = mutual_info_classif(X, y)\n",
        "feature_scores = pd.DataFrame({'Feature': X.columns, 'Mutual_Information': mutual_info})\n",
        "feature_scores = feature_scores.sort_values(by=['Mutual_Information'], ascending=False)\n",
        "\n",
        "\n",
        "# Display mutual information scores in a table\n",
        "display(feature_scores)\n",
        "\n"
      ],
      "metadata": {
        "id": "UMXqhEcfehhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Model Development"
      ],
      "metadata": {
        "id": "HE1cw-JEidGz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Models with basic parameters**"
      ],
      "metadata": {
        "id": "cH6i0Cei9FQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import TRUE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from IPython.display import display\n",
        "\n",
        "# Load Dataset\n",
        "data = pd.read_csv(\"modified_dataset.csv\")\n",
        "\n",
        "# Feature Selection\n",
        "features = ['url_length', 'subdomain_count', 'https', \"-\", \"_\", \"%\", \"/\", \".\", \"#\",\n",
        "            \"has_ip_address\", \"query_parameters_count\"]\n",
        "X = data[features]\n",
        "y = data['ClassLabel']  # Target variable\n",
        "\n",
        "# Handle missing values (fill with median)\n",
        "X.fillna(X.median(), inplace=True)\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and evaluate multiple models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
        "    \"SVM\": SVC(probability=True),\n",
        "    \"MLP\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500)\n",
        "}\n",
        "\n",
        "# Cross-validation setup\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Evaluate models using cross-validation\n",
        "kfold_results = {}\n",
        "for model_name, model in models.items():\n",
        "    scores = cross_val_score(model, X_scaled, y, cv=kf, scoring='accuracy')\n",
        "    kfold_results[model_name] = {\n",
        "        \"Model\": model_name,\n",
        "        \"Mean Accuracy\": np.mean(scores),\n",
        "        \"Standard Deviation\": np.std(scores)\n",
        "    }\n",
        "\n",
        "# Store results in a list of dictionaries\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
        "# Display the DataFrame\n",
        "\n",
        "   # Extract precision, recall, and F1-score for each class\n",
        "    report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
        "    precision = report_dict['weighted avg']['precision']\n",
        "    recall = report_dict['weighted avg']['recall']\n",
        "    f1_score = report_dict['weighted avg']['f1-score']\n",
        "\n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1_score,\n",
        "        'ROC-AUC': roc_auc,\n",
        "        'Confusion Matrix': conf_matrix,\n",
        "    })\n",
        "\n",
        "# Create a Pandas DataFrame from the results\n",
        "results_df = pd.DataFrame(results)\n",
        "kfold_results_df = pd.DataFrame(kfold_results.values())\n",
        "\n",
        "# Reorder columns\n",
        "kfold_results_df = kfold_results_df[['Model', 'Mean Accuracy', 'Standard Deviation']]\n",
        "\n",
        "# Display the DataFrame\n",
        "display(results_df)\n",
        "display(kfold_results_df)"
      ],
      "metadata": {
        "id": "AoeAkr3I-jKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZRFh8EO4sSfp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "0bZ21hZvjGoD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparamter Tuning using grid search**"
      ],
      "metadata": {
        "id": "qw3UKYXTcV7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import TRUE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from IPython.display import display\n",
        "\n",
        "# Load Dataset\n",
        "data = pd.read_csv(\"modified_dataset.csv\")\n",
        "\n",
        "# Feature Selection\n",
        "features = ['url_length', 'subdomain_count', 'https', \"-\", \"_\", \"%\", \"/\", \".\", \"#\",\n",
        "            \"has_ip_address\", \"query_parameters_count\"]\n",
        "X = data[features]\n",
        "y = data['ClassLabel']  # Target variable\n",
        "\n",
        "# Handle missing values (fill with median)\n",
        "X.fillna(X.median(), inplace=True)\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define models and parameter grids for tuning\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
        "    \"SVM\": SVC(probability=True),\n",
        "    \"MLP\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500)\n",
        "}\n",
        "\n",
        "# Define models and parameter grids for tuning\n",
        "param_grids = {\n",
        "    \"Logistic Regression\": {\n",
        "        'C': [0.01, 0.1, 1, 10, 100],\n",
        "        'solver': ['liblinear', 'lbfgs']\n",
        "    },\n",
        "    \"Decision Tree\": {\n",
        "        'max_depth': [5, 10, 20, None],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    \"Random Forest\": {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [10, 20, None],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    \"SVM\": {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf']\n",
        "    },\n",
        "    \"MLP\": {\n",
        "        'hidden_layer_sizes': [(50,), (100,), (100, 50)],\n",
        "        'activation': ['relu', 'tanh'],\n",
        "        'solver': ['adam', 'sgd'],\n",
        "        'alpha': [0.0001, 0.001, 0.01]\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "# Perform hyperparameter tuning and evaluate models\n",
        "cv_results = {}\n",
        "for model_name, param_grid in param_grids.items():\n",
        "    print(f\"Tuning {model_name}...\")\n",
        "    model = models[model_name]  # Get model instance from dictionary\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=kf, scoring='accuracy', n_jobs=-1, verbose=2)\n",
        "    grid_search.fit(X_scaled, y)\n",
        "\n",
        "    # Store results\n",
        "    best_params = grid_search.best_params_\n",
        "    best_score = grid_search.best_score_\n",
        "    cv_results[model_name] = {\n",
        "        \"Best Parameters\": best_params,\n",
        "        \"Best Accuracy\": best_score\n",
        "    }\n",
        "\n",
        "# Print and log results\n",
        "log_data = []\n",
        "for model, result in cv_results.items():\n",
        "    print(f\"{model}: Best Accuracy = {result['Best Accuracy']:.4f}, Best Parameters = {result['Best Parameters']}\")\n",
        "    log_data.append([model, result['Best Accuracy'], result['Best Parameters']])\n",
        "\n",
        "# Save tuning results to CSV\n",
        "df_log = pd.DataFrame(log_data, columns=['Model', 'Best Accuracy', 'Best Parameters'])\n",
        "df_log.to_csv(\"Model_Tuning_Results.csv\", index=False)\n",
        "\n",
        "print(\"Hyperparameter tuning complete! Results saved in Model_Tuning_Results.csv\")\n"
      ],
      "metadata": {
        "id": "G9a1F121j6AS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Optimisation, Validation Curves, Over/Under fitting**"
      ],
      "metadata": {
        "id": "UKYXRbZWsVWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import TRUE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from IPython.display import display\n",
        "\n",
        "# Load Dataset\n",
        "data = pd.read_csv(\"modified_dataset.csv\")\n",
        "\n",
        "# Feature Selection\n",
        "features = ['url_length', 'subdomain_count', 'https', \"-\", \"_\", \"%\", \"/\", \".\", \"#\",\n",
        "            \"has_ip_address\", \"query_parameters_count\"]\n",
        "X = data[features]\n",
        "y = data['ClassLabel']  # Target variable\n",
        "\n",
        "# Handle missing values (fill with median)\n",
        "X.fillna(X.median(), inplace=True)\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define models and parameter grids for tuning\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(C=0.1, solver='lbfgs'),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(max_depth=10, min_samples_split=10),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=10),\n",
        "    \"SVM\": SVC(C=10, kernel='rbf'),\n",
        "    \"MLP\": MLPClassifier(hidden_layer_sizes=(100,50), activation='tanh', solver='adam', alpha=0.001, max_iter=500)\n",
        "}\n",
        "\n",
        "# Function to plot learning curves\n",
        "def plot_learning_curve(model, X, y, model_name):\n",
        "    train_sizes, train_scores, val_scores = learning_curve(model, X, y, cv=5, scoring='accuracy', n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 10))\n",
        "\n",
        "    train_mean = np.mean(train_scores, axis=1)\n",
        "    train_std = np.std(train_scores, axis=1)\n",
        "    val_mean = np.mean(val_scores, axis=1)\n",
        "    val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Training Accuracy')\n",
        "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='blue', alpha=0.2)\n",
        "    plt.plot(train_sizes, val_mean, 'o-', color='red', label='Validation Accuracy')\n",
        "    plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color='red', alpha=0.2)\n",
        "\n",
        "    plt.xlabel(\"Training Set Size\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(f\"Learning Curve: {model_name}\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Plot learning curves for all models\n",
        "for model_name, model in models.items():\n",
        "    plot_learning_curve(model, X_scaled, y, model_name)\n",
        "\n",
        "# Feature Importance (for Decision Tree & Random Forest)\n",
        "def plot_feature_importance(model, model_name):\n",
        "    feature_importance = model.feature_importances_\n",
        "    sorted_idx = np.argsort(feature_importance)\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.barh(np.array(features)[sorted_idx], feature_importance[sorted_idx], color='teal')\n",
        "    plt.xlabel(\"Feature Importance\")\n",
        "    plt.title(f\"Feature Importance: {model_name}\")\n",
        "    plt.show()\n",
        "\n",
        "# Train tree-based models and plot feature importance\n",
        "tree_models = [\"Decision Tree\", \"Random Forest\"]\n",
        "for model_name in tree_models:\n",
        "    model = models[model_name].fit(X_scaled, y)\n",
        "    plot_feature_importance(model, model_name)\n",
        "\n",
        "print(\"Analysis complete! Check the plots for insights.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "wS4jcTpgsNBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Validation for performance esitmates**"
      ],
      "metadata": {
        "id": "mB2d8smp1ULZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import TRUE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from IPython.display import display\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load Dataset\n",
        "data = pd.read_csv(\"modified_dataset.csv\")\n",
        "\n",
        "# Feature Selection\n",
        "features = ['url_length', 'subdomain_count', 'https', \"-\", \"_\", \"%\", \"/\", \".\", \"#\",\n",
        "            \"has_ip_address\", \"query_parameters_count\"]\n",
        "X = data[features]\n",
        "y = data['ClassLabel']  # Target variable\n",
        "\n",
        "# Handle missing values (fill with median)\n",
        "X.fillna(X.median(), inplace=True)\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split training data into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define models and parameter grids for tuning\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(C=0.1, solver='lbfgs'),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(max_depth=10, min_samples_split=10),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=10),\n",
        "    \"SVM\": SVC(C=10, kernel='rbf'),\n",
        "    \"MLP\": MLPClassifier(hidden_layer_sizes=(100,50), activation='tanh', solver='adam', alpha=0.001, max_iter=500)\n",
        "}\n",
        "\n",
        "# Define models with pipelines\n",
        "models = {\n",
        "    \"Logistic Regression\": Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', LogisticRegression(C=0.1, solver='lbfgs'))\n",
        "    ]),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(max_depth=10, min_samples_split=10),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=10),\n",
        "    \"SVM\": Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', SVC(C=10, kernel='rbf'))\n",
        "    ]),\n",
        "    \"MLP\": Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', MLPClassifier(hidden_layer_sizes=(100,), activation='tanh', solver='adam', alpha=0.001, max_iter=500))\n",
        "    ])\n",
        "}\n",
        "\n",
        "# Nested Cross-Validation Setup\n",
        "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "inner_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform Nested CV Evaluation\n",
        "cv_results = {}\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Evaluating {model_name} using Nested Cross-Validation...\")\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=outer_cv, scoring='accuracy', n_jobs=-1)\n",
        "    mean_score, std_score = np.mean(scores), np.std(scores)\n",
        "\n",
        "    # Store results\n",
        "    cv_results[model_name] = {\n",
        "        \"Mean Accuracy\": mean_score,\n",
        "        \"Std Deviation\": std_score\n",
        "    }\n",
        "\n",
        "# Print results\n",
        "for model, result in cv_results.items():\n",
        "    print(f\"{model}: Mean Accuracy = {result['Mean Accuracy']:.4f}, Std Dev = {result['Std Deviation']:.4f}\")\n",
        "\n",
        "# Evaluate final models on the validation set\n",
        "val_results = {}\n",
        "for model_name, model in models.items():\n",
        "       model.fit(X_train, y_train)\n",
        "       val_accuracy = model.score(X_val, y_val)  # Use X_val and y_val here\n",
        "       val_results[model_name] = val_accuracy\n",
        "\n",
        "\n",
        "# Print validation results\n",
        "print(\"\\nFinal Validation Set Performance:\")\n",
        "for model, acc in val_results.items():\n",
        "    print(f\"{model}: Validation Accuracy = {acc:.4f}\")\n",
        "\n",
        "print(\"Nested Cross-Validation and Validation Set Evaluation Complete!\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6_bkpM0w1PHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Modelling & Ensemble Techniques"
      ],
      "metadata": {
        "id": "OceZ7dq17lxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementing Ensemble methods**"
      ],
      "metadata": {
        "id": "3h35WGBhE35_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load Dataset\n",
        "data = pd.read_csv(\"modified_dataset.csv\")\n",
        "\n",
        "# Feature Selection\n",
        "features = ['url_length', 'subdomain_count', 'https', \"-\", \"_\", \"%\", \"/\", \".\", \"#\",\n",
        "            \"has_ip_address\", \"query_parameters_count\"]\n",
        "X = data[features]\n",
        "y = data['ClassLabel']  # Target variable\n",
        "\n",
        "# Handle missing values (fill with median)\n",
        "X.fillna(X.median(), inplace=True)\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define base models for stacking\n",
        "base_models = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, max_depth=20, min_samples_split=5)),\n",
        "    ('svm', SVC(C=1, kernel='rbf', probability=True)),\n",
        "    ('mlp', MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', alpha=0.001, max_iter=500))\n",
        "]\n",
        "\n",
        "# Meta-model (Logistic Regression) for stacking\n",
        "stacking_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())\n",
        "\n",
        "# Boosting models\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=6, use_label_encoder=False, eval_metric='logloss')\n",
        "lgb_model = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=6)\n",
        "\n",
        "# Train and evaluate ensemble models\n",
        "ensemble_models = {\n",
        "    \"Stacking Classifier\": stacking_model,\n",
        "    \"XGBoost\": xgb_model,\n",
        "    \"LightGBM\": lgb_model\n",
        "}\n",
        "\n",
        "ensemble_results = {}\n",
        "for model_name, model in ensemble_models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    val_accuracy = model.score(X_val, y_val)\n",
        "    ensemble_results[model_name] = val_accuracy\n",
        "\n",
        "# Print validation results\n",
        "print(\"\\nEnsemble Model Performance on Validation Set:\")\n",
        "for model, acc in ensemble_results.items():\n",
        "    print(f\"{model}: Validation Accuracy = {acc:.4f}\")\n",
        "\n",
        "print(\"Ensemble Learning Implementation Complete!\")\n"
      ],
      "metadata": {
        "id": "6slxjQCj-jTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cross-validation to benchmark the performance of ensemble models against individual models**"
      ],
      "metadata": {
        "id": "50GEseiYqebo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load Dataset\n",
        "data = pd.read_csv(\"modified_dataset.csv\")\n",
        "\n",
        "# Feature Selection\n",
        "features = ['url_length', 'subdomain_count', 'https', \"-\", \"_\", \"%\", \"/\", \".\", \"#\",\n",
        "            \"has_ip_address\", \"query_parameters_count\"]\n",
        "X = data[features]\n",
        "y = data['ClassLabel']  # Target variable\n",
        "\n",
        "# Handle missing values (fill with median)\n",
        "X.fillna(X.median(), inplace=True)\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define individual models\n",
        "individual_models = {\n",
        "    \"Logistic Regression\": Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', LogisticRegression(C=1, solver='lbfgs'))\n",
        "    ]),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(max_depth=10, min_samples_split=10,),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=10),\n",
        "    \"SVM\": Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', SVC(C=10, kernel='rbf', probability=True))\n",
        "    ]),\n",
        "    \"MLP\": Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', MLPClassifier(hidden_layer_sizes=(100,50), activation='tanh', solver='adam', alpha=0.001, max_iter=500))\n",
        "    ])\n",
        "}\n",
        "\n",
        "# Define ensemble models\n",
        "base_models = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, max_depth=20, min_samples_split=5)),\n",
        "    ('svm', SVC(C=1, kernel='rbf', probability=True)),\n",
        "    ('mlp', MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', alpha=0.001, max_iter=500))\n",
        "]\n",
        "stacking_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=6, use_label_encoder=False, eval_metric='logloss')\n",
        "lgb_model = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=6)\n",
        "\n",
        "ensemble_models = {\n",
        "    \"Stacking Classifier\": stacking_model,\n",
        "    \"XGBoost\": xgb_model,\n",
        "    \"LightGBM\": lgb_model\n",
        "}\n",
        "\n",
        "# Cross-validation setup\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Evaluate individual models\n",
        "cv_results = {}\n",
        "for model_name, model in {**individual_models, **ensemble_models}.items():\n",
        "    print(f\"Evaluating {model_name} using Cross-Validation...\")\n",
        "    scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "    mean_score, std_score = np.mean(scores), np.std(scores)\n",
        "\n",
        "    # Store results\n",
        "    cv_results[model_name] = {\n",
        "        \"Mean Accuracy\": mean_score,\n",
        "        \"Std Deviation\": std_score\n",
        "    }\n",
        "\n",
        "# Print results\n",
        "print(\"\\nCross-Validation Performance Comparison:\")\n",
        "for model, result in cv_results.items():\n",
        "    print(f\"{model}: Mean Accuracy = {result['Mean Accuracy']:.4f}, Std Dev = {result['Std Deviation']:.4f}\")\n",
        "\n",
        "print(\"Cross-Validation Benchmarking Complete!\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nm2OMUjUmi-w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}